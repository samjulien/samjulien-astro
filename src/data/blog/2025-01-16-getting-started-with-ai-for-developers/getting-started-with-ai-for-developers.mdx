---
title: "Getting Started with AI for Developers"
slug: 'getting-started-with-ai-for-developers'
description: "The anti-hype guide for navigating the new world of AI engineering."
date: 2025-01-16
date_updated: 2025-01-16
ogimage: 'images/og-getting-started-with-ai-for-developers.png'
published: true
tags:
  - AI
---
When I first started to learn about AI engineering in October of 2023, I was overwhelmed with jargon, academic papers, and more acronyms than I could handle. NLP? RAG? LLMs? DPO? RLHF? My head was spinning. I looked around for resources targeted at web developers new to AI, but couldn't find what I wanted. I needed someone to orient me to the landscape, give me a map, and help me figure out which direction to go. Instead, I just kept finding a bunch of Machine Learning resources and more confusion.

I've been a friend and follower of Shawn Wang ([swyx](https://swyx.io/)) since his frontend days, so I started with his work on [Latent Space](https://www.latent.space/) and [The Rise of the AI Engineer](https://www.latent.space/p/ai-engineer). Eventually, I found my way around and learned enough to join [Writer](https://www.writer.com), an enterprise AI platform, as their Director of Developer Relations in spring 2024. It wasn't easy though, and I could have really used a practical, high-level guide to help me understand the landscape and get started.

So, as is my custom, whether with [Developer Relations](http://www.gettingstartedindevrel.com), [AWS](https://www.samjulien.com/where-to-start-with-aws-as-a-developer), or [Obsidian](https://www.samjulien.com/get-started-with-obsidian-as-a-developer), I'm creating the article I wished existed when I was getting started.

In this article, I'll break down my experience into high-level principles to approach the world of AI engineering and then practical strategies for getting started. As always, this is based on my experience - take what works for you and adapt it to your needs!

## Principles for understanding the shift to AI engineering

### Principle 1: AI is not just hype
Like many developers, I was initially skeptical of AI &mdash; we've all seen enough hype cycles in tech to develop a healthy dose of cynicism. But AI is not just hype &mdash; it's based on decades of research, and it stands to literally revolutionize our entire society. 

In his influential talk ["Opportunities in AI"](https://www.youtube.com/watch?v=5p248yoa3oE), Andrew Ng emphasizes that the current AI revolution is built on decades of research finally reaching practical application.


### Principle 2: The stakes are incredibly high
AGI
Billionaires racing for more power and money, will sacrifice nearly anything.

There are four major areas of both conflict and growth currently shaping the future of AI:
- Data: who owns and controls training data
- GPU/Inference: how we process and run models efficiently
- Multimodality: competition in different types of AI like image, video, and speech
- LLMOps: how we build and deploy AI applications

Understanding these battles helps you see where the opportunities lie for developers.

It's not an exaggeration to say that this is an "all of the marbles" scenario for humanity, and it's massively important that we approach it with care. If we're not careful, an unprecedented concentration of power could happen within our lifetimes. It's my goal to contribute to the spread of this knowledge and empower as many kind, good-hearted developers around the world to make a difference in their own community.

### Principle 3: The definition of work and the scale of possibility are fundamentally changing



### Principle 4: Development work is evolving (not disappearing) and you must adapt.

Remember building applications that pull in data and display it for analysis? Now you can generate that code using LLMs and then feed the data right back into them for automated analysis. The scale at which we can develop has radically changed. Junior developers actually have an advantage here because they don't have any preconceptions about what's possible.

At Writer, I see this every day - companies using LLMs to automate product descriptions across different retail sites, each with their own specific requirements. It's not flashy, but it saves enormous amounts of time and reduces errors. This immediate practical value is why AI has become the fastest-adopted new technology I've ever seen.

This shift is part of what Shawn calls ["The Rise of the AI Engineer"](https://www.latent.space/p/ai-engineer) - a fundamental change in how we approach development. 

Will AI replace developers? That's certainly the stated goal of several companies. But having worked directly with enterprise AI tools, I can tell you we're in the middle of a transformation rather than a replacement. We might not need developers to build UIs before long, but we'll absolutely need people who can orchestrate AI tools, review AI-generated code, and design complex systems.


## Strategies for shifting into AI engineering
The good news is that there is currently not enough engineering talent to usher in this new era.

Companies seem to be over-correcting for remote work during COVID and only wanting to hire in San Francisco and New York, but this isn't sustainable.

What does an AI engineer need to do their job?

### Strategy 1: Use AI products to prototype and learn the fundamentals of interacting with LLMs
You don't need a deep ML background to become an AI engineer, but you do need to understand:
- How to work with LLMs effectively across text, images, and other modalities
- Basic prompt engineering principles
- When to use AI and when not to

Luckily, many AI products provide a smooth onramp to learning the fundamentals of interacting with LLMs. You can use ChatGPT, Anthropic's Claude, or other AI products to learn the basics of prompting and get familiar with how to interact with LLMs.
Using an LLM:
How to interact with it
Prompting

Instructor prompt design site: https://python.useinstructor.com/prompting/thought_generation/chain_of_thought_zero_shot/thread_of_thought/

Sarah's prompting guide: https://exaai.notion.site/Prompt-Engineering-Best-Practices-0839585d4bce4c6abb0b551b2107a92a

Bringing data in through context

Multi-modality:
Computer Vision
Automatic speech recognition (ASR)

These products also introduce you to more advanced concepts in AI engineering. For example, web search is a subtle introduction to tool calling, while Deep Research by ChatGPT and Google Gemini is an introduction to agents.

For those just starting out, I recommend DeepLearning.AI's [Generative AI for Everyone](https://www.coursera.org/learn/generative-ai-for-everyone/) course

### Strategy 2: Learn the key skills for AI engineering by building
Once you're familiar with the basics of prompting, bringing in data or other modalities to LLMs, and the extent of their capabilities, it's time to start building with the models themselves through APIs and SDKs. These are the essential skills, as they represent the evolution of backend engineering and likely most of web development.

The most immediate opportunity for web developers is in combining existing AI tools effectively. I see successful AI engineers spending more time on:
- Integrating AI capabilities into existing applications
- Implementing RAG (Retrieval Augmented Generation)
- Building systems that combine multiple AI tools
- Building AI agents

Skills you already know:
Debugging
Testing 
Insert other core engineering skills

The key is understanding both:
- What AI can do well (code generation, data analysis, content creation)
- What still needs human oversight (system architecture, user experience, business logic)

AI stack or reasoning stack
LLM
Data (RAG, context)
UX/UI

Picking a model:
Which model is the best fit? How do you know?
LLM leaderboards
Benchmarks
Datasets

LLMs via APIs and SDKs

Note: Though many tools now offer JavaScript/TypeScript SDKs, you will inevitably need to learn at least some Python. I've been learning Python gradually as needed, using LLMs to help with the transition. LLMs are great at translating between languages!

Code generation
Bolt
Replit
Cursor
Windsurf

Bringing data in:
RAG
Data processing
Data engineering

What to do with it

Multi-modality:
Image generation
Computer Vision
Automatic speech recognition (ASR)
Text-to-audio
Text-to-video

Function calling


I highly recommend checking out DeepLearning.AI's [short courses](https://www.deeplearning.ai/short-courses/), which provide an excellent foundation in these concepts. I also really like Scrimba's [AI Engineering path](https://scrimba.com/paths/ai-engineering).

Following [swyxio/ai-notes](https://github.com/swyxio/ai-notes) for curated resources

level up course
Chip's book 

### Strategy 3: Cross the divide into production AI engineering
Where the real money is
Escaping POC purgatory
LLMs are non-deterministic

Advanced RAG
Graph RAG
Jason Liu

Testing LLM output
LLM unit tests
Evals
Quantifying our vibes

https://parlance-labs.com/education/evals/
https://forestfriends.tech/
https://wandb.ai/site/courses/evals/?utm_source=discord&utm_medium=social&utm_campaign=course_evals
Hamel and Shreya's course

LLM-as-judge
https://hamel.dev/blog/posts/llm-judge/

Eugene
https://eugeneyan.com/writing/llm-evaluators/


Hamel
https://hamel.dev/blog/posts/evals/

Shreya


https://www.firecrawl.dev/blog/crawlbench-llm-extraction

https://langfuse.com/

Function calling
Structured input
Structured output

Orchestrating multiple LLMs
Agents

### Strategy 4: Learn advanced topics as you can
Either fun/hobby or a different career  path, but likely not the core of AI engineering

Where to host a model?
Inference


Self-hosting models

LLMOps

Running models locally
LMStudio for running models locally: https://lmstudio.ai/

Latency
Cost
GPUs
Modal
Latent Space on Modal: https://www.latent.space/p/modal

Charles
Charles twitter: https://x.com/charles_irl

GPU glossary: https://modal.com/gpu-glossary/readme


Open source models
Closed source vs open source LLMs
Nathan Lambert

Fine-tuning

### Strategy 5: Staying current by ignoring the hype and followi by the signal
One of the biggest challenges in AI engineering is keeping up with the rapid pace of change. 

Three sources of signal

Follow smart people
Applied LLMs crew
Nathan Lambert

Start learning about AI and ML research
Wade into research
https://www.latent.space/p/2025-papers

Eugene's links
Eugene Yan's write-up on how to start a paper club: https://eugeneyan.com/writing/paper-club/
Eugene Yan's list of notable papers: https://github.com/eugeneyan/llm-paper-notes
Paper club
NeurIPS

Discord servers
Join communities like [Latent Space](https://www.latent.space/) to stay current

Remember, you don't need to know everything. Focus on understanding the fundamentals and keeping an eye on major developments that affect your work directly. The developers who will thrive aren't necessarily the ones who know the most about machine learning theory - they're the ones who can effectively combine AI capabilities with solid engineering principles to solve real problems.

## The Path Forward

Nobody knows exactly how fast AI will transform development - I've heard predictions ranging from "we've got a decade before AGI" to "AI agents will change everything within a year." The reality is probably somewhere in between, but the direction is clear.

Here's what I recommend focusing on:
1. Get comfortable with AI tools - they're becoming as fundamental as learning a new programming language
2. Build your orchestration skills - the ability to combine different AI tools effectively is increasingly valuable
3. Maintain your engineering judgment - AI can generate code, but understanding architecture and user needs remains crucial
4. Stay curious but practical - focus on solving real problems rather than chasing the latest AI trend

You can do this! Reach out if you have questions.